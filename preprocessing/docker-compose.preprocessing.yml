services:
  #  run_qdrant_script:
  #    build:
  #      context: .
  #      dockerfile: Dockerfile.storing
  #    networks:
  #      - llm-to_prod_kafka-network

  run_spark_script:
    build:
      context: .
      dockerfile: Dockerfile.spark_preprocessing
    environment:
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_LOCAL_IP=0.0.0.0
      - SPARK_DRIVER_HOST=preprocessing
      - SPARK_DRIVER_PORT=7001
      - SPARK_DRIVER_BINDADDRESS=0.0.0.0
      - SPARK_BLOCKMANAGER_PORT=7002
      - SPARK_WORKER_MEMORY=4g
      - SPARK_WORKER_CORES=2
      - HF_HOME=/tmp/huggingface_cache
    ports:
      - "7001:7001"
      - "7002:7002"
    command: >
      spark-submit
      --master spark://spark:7077
      --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.4
      --conf spark.executor.memory=4g
      --conf spark.driver.memory=4g
      --conf spark.executor.cores=2
      --conf spark.driver.cores=2
      --conf spark.streaming.kafka.maxRatePerPartition=100
      /app/src/spark_preprocessing.py


configs:
  qdrant_config:
    content: |
      log_level: INFO      

networks:
  llm-to_prod_kafka-network:
    external: true
